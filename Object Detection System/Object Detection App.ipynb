{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3981d495-1f58-49e5-bf1c-8fbf61adf600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbeae7e4-781f-40fe-b6e4-b7f0c873555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    '''\n",
    "    Configuration settings for Object Detection Project\n",
    "    '''\n",
    "    MODEL_WEIGHTS = 'yolov8n.pt'\n",
    "    CONFIDENCE_THRESHOLD = 0.5\n",
    "    device = 'cpu'\n",
    "\n",
    "    # Visual Settings\n",
    "    BOX_COLOR = (0, 255, 0) # green\n",
    "    TEXT_COLOR = (0,0,0) # bLack\n",
    "    TEXT_BG_COLOR = (0, 255, 0)\n",
    "\n",
    "class ObjectDetector:\n",
    "    def __init__(self, model_path=None):\n",
    "        '''\n",
    "        Initialize the YOLO detector\n",
    "        '''\n",
    "        self.model_name = model_path if model_path else Config.MODEL_WEIGHTS\n",
    "        print(f\"Loading YOLO model: {self.model_name}\")\n",
    "        try:\n",
    "            self.model = YOLO(self.model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"error loading model: {e}\")\n",
    "            raise\n",
    "    def predict_frame(self, frame):\n",
    "        '''\n",
    "        Runs inference on a single frame.\n",
    "        '''\n",
    "        results = self.model(frame, conf=Config.CONFIDENCE_THRESHOLD, verbose = False)\n",
    "        return results[0] # because we sent one frame\n",
    "    def annotate_frame(self, frame, result):\n",
    "        '''\n",
    "        Draws bounding boxes and labels on the frame using OpenCV.\n",
    "        '''\n",
    "        annotated_frame = frame.copy()\n",
    "        #Iterating through detections\n",
    "        for box in result.boxes:\n",
    "            # Getting box coordinates\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            # Get Confidence and class info\n",
    "            conf = float(box.conf[0])\n",
    "            cls = int(box.cls[0])\n",
    "            label = f\"{self.model.names[cls]} {conf:.2f}\"\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(annotated_frame, (x1,y1), (x2,y2), Config.BOX_COLOR, 2)\n",
    "            # Draw Label Background\n",
    "            (w,h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "            cv2.rectangle(annotated_frame, (x1, y1 -20), (x1 + w, y1), Config.TEXT_BG_COLOR, -1 )\n",
    "            # Draw Text\n",
    "            cv2.putText(annotated_frame, label, (x1,y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, Config.TEXT_COLOR, 1)\n",
    "        return annotated_frame\n",
    "    def run_live_stream(self, source=0):\n",
    "        '''\n",
    "        Capture video from a webcam or video file and runs detection.\n",
    "        '''\n",
    "        cap = cv2.VideoCapture(source)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video source {source}\")\n",
    "            return\n",
    "        print(f\"Starting detection on source: {source}\")\n",
    "        print(f\"press 'q' to exit\")\n",
    "\n",
    "        # Calculate FPS\n",
    "        prev_frame_time = 0\n",
    "        new_frame_time = 0\n",
    "\n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print('End of stream or failed to read frame')\n",
    "                break\n",
    "            # 1.Inference\n",
    "            result = self.predict_frame(frame)\n",
    "            # 2. Annotation\n",
    "            display_frame = self.annotate_frame(frame, result)\n",
    "            # 3. Calculate and display FPS\n",
    "            new_frame_time = time.time()\n",
    "            new_frame_time = time.time()\n",
    "            fps = 1 / (new_frame_time - prev_frame_time)\n",
    "            prev_frame_time = new_frame_time\n",
    "            cv2.putText(display_frame, f\"FPS: {int(fps)}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # 4. Show Frame\n",
    "            cv2.imshow(\"Object Detection System (YOLOv8)\", display_frame)\n",
    "\n",
    "            # Exit condition\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e371181-3388-48a5-b27b-0e01087927bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_custom_model(self, data_yaml_path, epochs=10):\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    results = model.train(data=data_yaml_path, epochs=epochs, imgsz=640)\n",
    "    print(\"Training complete. Best model saved as best.pt\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631d08d9-8d64-4ef1-8e6f-5fc70210c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO model: yolov8n.pt\n",
      "Launching Webcam...\n",
      "Starting detection on source: 0\n",
      "press 'q' to exit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize Detector\n",
    "    detector = ObjectDetector()\n",
    "    \n",
    "    # MODE SELECTION\n",
    "    # 1. Real-time Webcam Detection\n",
    "    print(\"Launching Webcam...\")\n",
    "    detector.run_live_stream(source=0)\n",
    "    \n",
    "    # 2. To run on a video file, uncomment below:\n",
    "    # detector.run_live_stream(source='path/to/your/video.mp4')\n",
    "    \n",
    "    # 3. To Train on Custom Data (requires a dataset.yaml), uncomment below:\n",
    "    # detector.train_custom_model('dataset.yaml', epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df245749-526b-489b-af3e-933ab3a66c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Training Process...\n",
      "Starting training... this may take a while depending on your computer speed.\n",
      "Ultralytics 8.3.240  Python-3.12.3 torch-2.7.1+cu118 CUDA:0 (Quadro P1000, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=datasets/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=my_custom_model2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Machine Learning\\Internship\\object detection\\runs\\detect\\my_custom_model2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 89.922.3 MB/s, size: 85.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Machine Learning\\Internship\\object detection\\datasets\\train\\labels.cache... 132 images, 9 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 132/132 74.8Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 3.50.6 MB/s, size: 88.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Machine Learning\\Internship\\object detection\\datasets\\valid\\labels... 38 images, 1 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 38/38 345.9it/s 0.1s.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Machine Learning\\Internship\\object detection\\datasets\\valid\\labels.cache\n",
      "Plotting labels to D:\\Machine Learning\\Internship\\object detection\\runs\\detect\\my_custom_model2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Machine Learning\\Internship\\object detection\\runs\\detect\\my_custom_model2\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      1.17G      1.259      3.369      1.569          7        640: 100% ━━━━━━━━━━━━ 17/17 1.3it/s 13.3s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.2it/s 0.9s0.7s\n",
      "                   all         38         49    0.00412      0.959      0.595      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      1.28G      1.042      2.032      1.225         10        640: 100% ━━━━━━━━━━━━ 17/17 2.0it/s 8.4s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.3it/s 0.7s0.5s\n",
      "                   all         38         49     0.0043          1      0.777      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      1.28G      1.108      1.815      1.222         11        640: 100% ━━━━━━━━━━━━ 17/17 2.1it/s 8.2s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.7it/s 0.8s0.6s\n",
      "                   all         38         49     0.0043          1      0.728      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      1.31G       1.13      1.665      1.258         14        640: 100% ━━━━━━━━━━━━ 17/17 2.1it/s 8.0s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.9it/s 0.6s0.5s\n",
      "                   all         38         49       0.65       0.53       0.62      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      1.32G      1.128      1.815      1.255          6        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.5it/s 0.7s0.5s\n",
      "                   all         38         49      0.922      0.722      0.897      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      1.34G      1.055      1.632      1.209         10        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.9it/s 0.6s0.5s\n",
      "                   all         38         49      0.596      0.735      0.747       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      1.36G      1.079      1.543      1.206         12        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.9it/s 0.6s0.5s\n",
      "                   all         38         49      0.602      0.918      0.822      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      1.38G      1.011      1.495      1.189         11        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.9it/s 0.6s0.5s\n",
      "                   all         38         49      0.723      0.798      0.736       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50       1.4G      1.069      1.458      1.237         16        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.9it/s 0.6s0.5s\n",
      "                   all         38         49      0.888      0.878       0.93      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      1.41G      1.033      1.299      1.237         11        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.1it/s 0.6s0.5s\n",
      "                   all         38         49      0.888      0.898      0.933       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      1.43G      1.011      1.229      1.186         11        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.2it/s 0.6s0.4s\n",
      "                   all         38         49      0.851      0.878      0.935      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      1.44G     0.9817      1.201      1.155          9        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.7it/s 0.6s0.5s\n",
      "                   all         38         49      0.978      0.888      0.949      0.636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      1.46G      1.009      1.219      1.161          8        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.9it/s 0.6s0.5s\n",
      "                   all         38         49      0.955      0.959      0.974      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      1.48G     0.9716      1.187      1.191          7        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.4s\n",
      "                   all         38         49      0.917      0.959       0.96      0.666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50       1.5G     0.9247      1.012      1.128         11        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.1it/s 0.6s0.4s\n",
      "                   all         38         49      0.956      0.877      0.925      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      1.51G     0.9564      1.075      1.168         10        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.756      0.821      0.766       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      1.53G     0.9228       1.08      1.146          6        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.918      0.686      0.856      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      1.55G     0.9174       1.07      1.164          6        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.2it/s 0.6s0.4s\n",
      "                   all         38         49      0.914      0.959      0.918      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      1.57G     0.8921      0.952      1.094         13        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.9it/s 0.6s0.5s\n",
      "                   all         38         49      0.968      0.939      0.984      0.687\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      1.57G     0.9041     0.9638      1.101          5        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.966      0.939      0.977       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50       1.6G     0.8621     0.9303      1.097          8        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.1it/s 0.6s0.5s\n",
      "                   all         38         49       0.95      0.918      0.969       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      1.62G     0.7751     0.8652      1.053         15        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.4s\n",
      "                   all         38         49      0.996      0.939      0.983      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      1.63G     0.7868     0.8444      1.036         12        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.8it/s 0.6s0.5s\n",
      "                   all         38         49       0.94      0.963      0.987      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      1.65G     0.8325     0.8694      1.083          5        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.2it/s 0.6s0.4s\n",
      "                   all         38         49      0.958      0.939      0.981      0.707\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      1.67G     0.8613     0.8896      1.092         14        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.978      0.926      0.984      0.709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      1.69G     0.8304     0.8457      1.084         10        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.2it/s 0.6s0.5s\n",
      "                   all         38         49      0.957      0.939      0.986      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50       1.7G      0.819      0.827      1.086         10        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.995      0.939      0.975      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      1.71G     0.8804     0.8216      1.142         11        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.994      0.898      0.984      0.697\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      1.74G     0.8216     0.7872      1.103          9        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.2it/s 0.6s0.5s\n",
      "                   all         38         49      0.993      0.898      0.976      0.715\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      1.75G     0.8178     0.7685      1.104          6        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.4s\n",
      "                   all         38         49      0.958      0.935      0.969      0.704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      1.77G     0.8141     0.7792       1.11         13        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.2it/s 0.6s0.5s\n",
      "                   all         38         49      0.955      0.939      0.972      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      1.79G      0.774     0.7549      1.049         11        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.9it/s 0.6s0.5s\n",
      "                   all         38         49      0.978      0.913      0.977       0.72\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      1.81G     0.7585     0.7148      1.054         13        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.1it/s 0.6s0.5s\n",
      "                   all         38         49      0.959      0.959       0.98      0.716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      1.82G     0.7161     0.6347      1.009         14        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.4s\n",
      "                   all         38         49      0.976       0.98      0.989      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      1.84G     0.7087     0.7363      1.024          4        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.4s\n",
      "                   all         38         49      0.937       0.98      0.984      0.747\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      1.84G     0.7273     0.6788      1.041          5        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.4s\n",
      "                   all         38         49      0.978      0.939       0.98       0.71\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      1.87G     0.7029     0.6348      1.037          7        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.5it/s 0.5s0.4s\n",
      "                   all         38         49      0.974      0.939       0.98      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      1.89G     0.7097     0.6445      1.036          9        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.1it/s 0.6s0.5s\n",
      "                   all         38         49      0.973      0.918       0.98      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      1.91G     0.6564     0.6429       1.02          7        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.0it/s 0.6s0.5s\n",
      "                   all         38         49      0.937      0.939      0.974      0.725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      1.93G     0.6937     0.6242      1.027         13        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.958      0.938      0.969      0.731\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      1.94G     0.6403     0.6985     0.9765          5        640: 100% ━━━━━━━━━━━━ 17/17 2.2it/s 7.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.953      0.939      0.965      0.732\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      1.96G     0.6357     0.6705      0.967          4        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.4s\n",
      "                   all         38         49       0.94      0.959      0.966      0.713\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      1.97G      0.619     0.6683     0.9488          6        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.941      0.977      0.983      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      1.98G     0.5886     0.6246     0.9266          6        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.5s\n",
      "                   all         38         49      0.957      0.959      0.987      0.707\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      2.01G     0.6101     0.6303     0.9686          5        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49       0.96      0.974      0.989      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      1.38G     0.5869     0.5937     0.9468          4        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.2it/s 0.6s0.4s\n",
      "                   all         38         49          1      0.932       0.99       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      1.38G     0.5858     0.6004     0.9421          5        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.4s\n",
      "                   all         38         49          1      0.936      0.989      0.711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      1.38G     0.5754     0.5881     0.9315          4        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49      0.995      0.939      0.989      0.716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      1.38G     0.5425     0.6023     0.9266          3        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s0.4s\n",
      "                   all         38         49          1      0.939      0.988      0.725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      1.38G     0.5406     0.5678     0.9461          3        640: 100% ━━━━━━━━━━━━ 17/17 2.3it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.3it/s 0.6s0.4s\n",
      "                   all         38         49       0.96      0.972      0.988      0.735\n",
      "\n",
      "50 epochs completed in 0.125 hours.\n",
      "Optimizer stripped from D:\\Machine Learning\\Internship\\object detection\\runs\\detect\\my_custom_model2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from D:\\Machine Learning\\Internship\\object detection\\runs\\detect\\my_custom_model2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating D:\\Machine Learning\\Internship\\object detection\\runs\\detect\\my_custom_model2\\weights\\best.pt...\n",
      "Ultralytics 8.3.240  Python-3.12.3 torch-2.7.1+cu118 CUDA:0 (Quadro P1000, 4096MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.5it/s 0.7s0.5s\n",
      "                   all         38         49      0.937       0.98      0.984      0.745\n",
      "Speed: 0.3ms preprocess, 9.9ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Machine Learning\\Internship\\object detection\\runs\\detect\\my_custom_model2\u001b[0m\n",
      "Training Complete!\n",
      "Your new brain is saved at: runs/detect/my_custom_model/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "def train_custom_model():\n",
    "    \"\"\"\n",
    "    Trains a YOLOv8 model on a custom dataset.\n",
    "    \"\"\"\n",
    "    print(\"Initializing Training Process...\")\n",
    "\n",
    "    # 1. Load a model\n",
    "    # We start with 'yolov8n.pt' (Nano) because it's fast and small.\n",
    "    # It already knows 80 basic objects, which helps it learn new ones faster (Transfer Learning).\n",
    "    model = YOLO('yolov8n.pt') \n",
    "\n",
    "    # 2. Train the model\n",
    "    # data: Path to'data.yaml' file \n",
    "    # epochs: How many times the model sees the data. 50-100 is standard for good results.\n",
    "    # imgsz: Image size. 640 is standard.\n",
    "    # batch: How many images to process at once. \n",
    "    try:\n",
    "        print(\"Starting training... this may take a while depending on your computer speed.\")\n",
    "        results = model.train(\n",
    "            data='datasets/data.yaml',  # CRITICAL: Point this to your config file\n",
    "            epochs=50,                  # Try 50 for a real result, 5 just to test code\n",
    "            imgsz=640,\n",
    "            batch=8,                    # Reduce if you run out of memory\n",
    "            name='my_custom_model'      # Name of the output folder\n",
    "        )\n",
    "        print(\"Training Complete!\")\n",
    "        print(f\"Your new brain is saved at: runs/detect/my_custom_model/weights/best.pt\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        print(\"Make sure your 'data.yaml' path is correct and your images are labeled!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have the 'datasets' folder structure set up before running this!\n",
    "    train_custom_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8b5c1-516b-47ca-bfae-a2afd7726f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
